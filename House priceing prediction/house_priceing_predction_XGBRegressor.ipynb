{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {
        "id": "lU28ad1Kvpon"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "train_d=pd.read_csv(\"train.csv\")\n",
        "test_d=pd.read_csv(\"test.csv\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "to know what is the best feauters to dealing with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {
        "id": "HmSeAOaVYTMi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SalePrice       1.000000\n",
            "OverallQual     0.790982\n",
            "GrLivArea       0.708624\n",
            "GarageCars      0.640409\n",
            "GarageArea      0.623431\n",
            "TotalBsmtSF     0.613581\n",
            "1stFlrSF        0.605852\n",
            "FullBath        0.560664\n",
            "TotRmsAbvGrd    0.533723\n",
            "YearBuilt       0.522897\n",
            "Name: SalePrice, dtype: float64 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "corr = train_d[[i for i in train_d.select_dtypes(\n",
        "    include=(\"int64\", \"float64\")).columns]].corr()\n",
        "                \n",
        "\n",
        "print(corr['SalePrice'].sort_values(ascending=False)[:10], '\\n')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "how much missing values in columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "metadata": {
        "id": "J4hlc0Fcvpos"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "thier are 19 columns with missing values\n",
            "(259, 'LotFrontage')\n",
            "(1369, 'Alley')\n",
            "(872, 'MasVnrType')\n",
            "(8, 'MasVnrArea')\n",
            "(37, 'BsmtQual')\n",
            "(37, 'BsmtCond')\n",
            "(38, 'BsmtExposure')\n",
            "(37, 'BsmtFinType1')\n",
            "(38, 'BsmtFinType2')\n",
            "(1, 'Electrical')\n",
            "(690, 'FireplaceQu')\n",
            "(81, 'GarageType')\n",
            "(81, 'GarageYrBlt')\n",
            "(81, 'GarageFinish')\n",
            "(81, 'GarageQual')\n",
            "(81, 'GarageCond')\n",
            "(1453, 'PoolQC')\n",
            "(1179, 'Fence')\n",
            "(1406, 'MiscFeature')\n"
          ]
        }
      ],
      "source": [
        "# for training dataset\n",
        "t_nul_col_with_number_of_misssing=[train_d[i].isnull().sum() for i in train_d.columns if train_d[i].isnull().any()]\n",
        "t_nul_col_with_name = [i for i in train_d.columns if train_d[i].isnull().any()]\n",
        "print(\n",
        "    f\"thier are {len(t_nul_col_with_number_of_misssing)} columns with missing values\")\n",
        "for i in range(len(t_nul_col_with_name)):\n",
        "\n",
        "    print(f\"{t_nul_col_with_number_of_misssing[i],t_nul_col_with_name[i]}\")\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 340,
      "metadata": {
        "id": "JFnbpjQeS4j0"
      },
      "outputs": [],
      "source": [
        "col_to_del=[\"Alley\",\"PoolQC\",\"Fence\",\"MiscFeature\",'LotFrontage',\"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\",\"FireplaceQu\",\"GarageType\",\"GarageYrBlt\",\"GarageFinish\",\"GarageQual\",\"GarageCond\"]\n",
        "train_d=train_d.drop(col_to_del,axis=1)\n",
        "# train_d=train_d.drop([\"SalePrice\"],axis=1)\n",
        "test_d=test_d.drop(col_to_del,axis=1)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "here we are imputing the train data because we have alot of missing values in the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 341,
      "metadata": {
        "id": "WWXNLGKaUX4l"
      },
      "outputs": [],
      "source": [
        "my_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "imputed_train_d=pd.DataFrame(my_imputer.fit_transform(train_d))\n",
        "imputed_train_d.columns=train_d.columns\n",
        "\n",
        "imputed_test_d = pd.DataFrame(my_imputer.fit_transform(test_d))\n",
        "imputed_test_d.columns = test_d.columns\n",
        "# to saving the data type of the columns\n",
        "imputed_train_d = imputed_train_d.astype(train_d.dtypes.to_dict())\n",
        "imputed_test_d = imputed_test_d.astype(test_d.dtypes.to_dict())\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "splitting the values to numeric and categorical values "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 342,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "ghzcTxE_Z2aQ",
        "outputId": "6735aac2-22db-457e-d87d-c43e29ca8c69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SalePrice       1.000000\n",
            "OverallQual     0.790982\n",
            "GrLivArea       0.708624\n",
            "GarageCars      0.640409\n",
            "GarageArea      0.623431\n",
            "TotalBsmtSF     0.613581\n",
            "1stFlrSF        0.605852\n",
            "FullBath        0.560664\n",
            "TotRmsAbvGrd    0.533723\n",
            "YearBuilt       0.522897\n",
            "YearRemodAdd    0.507101\n",
            "MasVnrArea      0.472614\n",
            "Fireplaces      0.466929\n",
            "BsmtFinSF1      0.386420\n",
            "WoodDeckSF      0.324413\n",
            "Name: SalePrice, dtype: float64 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "num_col_train=imputed_train_d.select_dtypes(include=(\"int64\",\"float64\")).columns\n",
        "cat_col_train=imputed_train_d.select_dtypes(include=(\"object\")).columns\n",
        "#  to find the corrlation between numerica values and the predict (SalePrice) column\n",
        "corr_num_col = imputed_train_d[num_col_train].corr()\n",
        "print(corr_num_col['SalePrice'].sort_values(ascending=False)[:15], '\\n')\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "here i will encoding the cat col data and concat it (after encoding id) with numirc col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {
        "id": "vYcdDOKOYeSa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\hussam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "OHE = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "OHE.fit(imputed_train_d[cat_col_train])\n",
        "cat_temp=pd.DataFrame(OHE.transform(imputed_train_d[cat_col_train]))\n",
        "cat_temp.columns=OHE.get_feature_names_out()\n",
        "\n",
        "# cat_temp=pd.get_dummies(imputed_train_d[cat_col_train])\n",
        "num_temp=imputed_train_d[num_col_train]\n",
        "\n",
        "# temp_d = pd.concat([cat_temp,imputed_train_d[\"SalePrice\"]], axis=1) \n",
        "# corr = temp_d.corr()\n",
        "# print(corr['SalePrice'].sort_values(ascending=False)[:20], '\\n')\n",
        "\n",
        "final_train_d = pd.concat([num_temp,cat_temp],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 344,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B4jqSOXtiRH",
        "outputId": "9d8b12bc-4925-4401-8e8b-a19dcc162651"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "225\n"
          ]
        }
      ],
      "source": [
        "num_col_test=imputed_test_d.select_dtypes(include=(\"int64\",\"float64\")).columns\n",
        "cat_col_test=imputed_test_d.select_dtypes(include=(\"object\")).columns\n",
        "\n",
        "\n",
        "# cat_temp=pd.get_dummies(imputed_test_d[cat_col_test])\n",
        "\n",
        "cat_temp=pd.DataFrame(OHE.transform(imputed_test_d[cat_col_test]))\n",
        "num_temp=imputed_test_d[num_col_test]\n",
        "cat_temp.columns=OHE.get_feature_names_out()\n",
        "\n",
        "final_test_d = pd.concat([num_temp,cat_temp],axis=1)\n",
        "print(len(final_test_d.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 345,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp_d = pd.concat([cat_temp, imputed_train_d[\"SalePrice\"]], axis=1)\n",
        "corr = temp_d.corr()\n",
        "most_corr_col_cat = corr['SalePrice'].sort_values(ascending=False)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### here i will find the score of the data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 367,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "def score_dataset(X, y, model=XGBRegressor()):\n",
        "    # Label encoding for categoricals\n",
        "    for colname in X.select_dtypes([\"category\"]):\n",
        "        X[colname] = X[colname].cat.codes\n",
        "    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n",
        "    log_y = np.log(y)\n",
        "    score = cross_val_score(\n",
        "        model, X, log_y, cv=5, scoring=\"neg_mean_squared_error\",\n",
        "    )\n",
        "    score = -1 * score.mean()\n",
        "    score = np.sqrt(score)\n",
        "    return score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 370,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "_1jcZKtkvpo0",
        "outputId": "2cffa18e-93ed-4c8a-eb23-3f12920b2ca5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\hussam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.13957235728211956"
            ]
          },
          "execution_count": 370,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(final_train_d.drop(\n",
        "    [\"SalePrice\"], axis=1), final_train_d['SalePrice'], train_size=0.8, test_size=0.2, random_state=0)\n",
        "\n",
        "model1 = XGBRegressor(n_estimators=5000,learning_rate=0.1)\n",
        "model1.fit(X_train[corr_num_col.index[:-1].append(most_corr_col_cat.index[1:])],\n",
        "            y_train,\n",
        "            early_stopping_rounds=5,\n",
        "           eval_set=[(X_valid[corr_num_col.index[:-1].append(most_corr_col_cat.index[1:])],\n",
        "                       y_valid)],\n",
        "           verbose=False)\n",
        "\n",
        "\n",
        "score_dataset(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 358,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4VK3pK3vpo0",
        "outputId": "047d41cf-668f-486a-f86a-975a3e66cc99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16644.47522474315\n"
          ]
        }
      ],
      "source": [
        "mse = mean_absolute_error(y_valid, model1.predict(\n",
        "    X_valid[corr_num_col.index[:-1].append(most_corr_col_cat.index[1:])]))\n",
        "print(mse)\n",
        "#\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 366,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(model1.predict(final_test_d[corr_num_col.index[:-1].append(\n",
        "    most_corr_col_cat.index[1:])]), columns=[\"SalePrice\"] ,index=test_d['Id']).to_csv(\"first_prediction.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
